{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3c2a9ef3-400a-4be7-874b-02f2fb425b5d",
      "metadata": {
        "id": "3c2a9ef3-400a-4be7-874b-02f2fb425b5d"
      },
      "source": [
        "# Example: Build a Hidden Markov Model of Daily Stock Excess Growth Rate\n",
        "This example will familiarize students with constructing an Observable Markov Model (OMM) of the excess growth rate of a ticker `XYZ` where we define the excess growth as:\n",
        "$$\n",
        "\\begin{equation*}\n",
        "R_{ij} \\equiv \\left(\\frac{1}{\\Delta{t}}\\right)\\cdot\\ln\\left(\\frac{S_{i,j}}{S_{i,j-1}}\\right) - \\bar{r}_{f}\n",
        "\\end{equation*}\n",
        "$$\n",
        "where $R_{ij}$ denotes the excess growth rate of equity $i$ at time $j$, $\\Delta{t}$ denotes the time-step between $j-1\\rightarrow{j}$ (units: years), $S_{i,\\star}$ denotes the share price of equity $i$ at time $\\star$, and $\\bar{r}_{f}$ denotes the annualized risk free rate. In this example, we build a model of daily return.\n",
        "\n",
        "## Model\n",
        "Describe the day-to-day variation of the excess growth using a fully observable Markov model $\\mathcal{M}$ represented by the tuple $\\mathcal{M} = (\\mathcal{S},\\mathcal{O},\\mathbf{P},\\mathbf{E})$; $\\mathcal{S}$ is the set of hidden states, $\\mathcal{O}$ is the set of observable states, $\\mathbf{T}$ is the transition matrix, i.e., $t_{ij}\\in\\mathbf{T}$ is the probability of moving from hidden state $i$ to hidden state $j$ in the next time step, and $\\mathbf{E}$ is the emission matrix. Because we are fully observable, the emission matrix $\\mathbf{E} = \\mathbf{I}$, where $\\mathbf{I}$ is the identity matrix.\n",
        "\n",
        "## Learning objectives\n",
        "* __Task 1__: Construct the states $\\mathcal{S}$, the emission matrix $\\mathbf{E}$ and transition matrix $\\hat{\\mathbf{T}}$\n",
        "    * `TODO`: Estimate the transition matrix $\\hat{\\mathbf{T}}$ from market data\n",
        "* __Task 2__: Simulate the Hidden Markov Model (HMM) for an average trading year\n",
        "    * `TODO`: Generate the stationary distribution from the estimated $\\hat{\\mathbf{T}}$ matrix\n",
        "    * `TODO`: Implement the `MARKOV-SIMULATION` pseudo code from the lecture to generate hypothetical return sequences\n",
        "* __Task 3__: Save the HMM model and other data to a file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f687d9d-00ea-4858-82ba-644a73ecb996",
      "metadata": {
        "id": "1f687d9d-00ea-4858-82ba-644a73ecb996"
      },
      "source": [
        "## Setup\n",
        "We set up the computational environment by including the `Include.jl` file. The `Include.jl` file loads external packages, various functions that we will use in the exercise, and custom types to model the components of our lab problem.\n",
        "* For additional information on functions and types used in this material, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/) and the [VLQuantitativeFinancePackage.jl documentation](https://github.com/varnerlab/VLQuantitativeFinancePackage.jl)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "31591712-2a05-4ea5-92d4-9f04eff6dd7c",
      "metadata": {
        "id": "31591712-2a05-4ea5-92d4-9f04eff6dd7c",
        "outputId": "5f95c1e8-e2f0-40ef-c301-8af48ed08dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'include' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c8ebd9a372ee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minclude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Include.jl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'include' is not defined"
          ]
        }
      ],
      "source": [
        "include(\"Include.jl\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eea45c8-3766-461c-bb13-6b3c8b2b7ebb",
      "metadata": {
        "id": "5eea45c8-3766-461c-bb13-6b3c8b2b7ebb"
      },
      "source": [
        "## Prerequisites: Load and clean the historical dataset\n",
        "We gathered a daily open-high-low-close `dataset` for each firm in the [S&P500](https://en.wikipedia.org/wiki/S%26P_500) from `01-03-2018` until `12-29-2024`, along with data for a few exchange-traded funds and volatility products during that time. In this block of code, we:\n",
        "* Load and clean the historical data; store the cleaned data in the `dataset` variable. We then calculate the expected excess return $\\mathbb{E}(R_{i})$ for each `ticker` in the `dataset.` Finally, you'll select a firm by changing the value in the `ticker` variable. We store the computed excess return for the `ticker` in the `Rᵢ` variable.\n",
        "\n",
        "Let's start by setting some constant values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc2d7320-62e2-44bb-911e-ef2e815be1ca",
      "metadata": {
        "id": "bc2d7320-62e2-44bb-911e-ef2e815be1ca"
      },
      "outputs": [],
      "source": [
        "risk_free_rate = 0.0421; # 17-Jun-2024 10-year treasury\n",
        "Δt = (1/252); # time step 1 x trading in units of years\n",
        "number_of_paths = 100; # number of potential futures should we look at\n",
        "blue_color = colorant\"rgb(68,152,242)\";\n",
        "ticker = \"JNJ\"; # This is the ticker we want to explore\n",
        "\n",
        "# palette -\n",
        "my_color_palette = Dict{Int64,RGB}();\n",
        "my_color_palette[0] = colorant\"#e5e5e5\";\n",
        "my_color_palette[1] = colorant\"#ff7d00\";\n",
        "my_color_palette[2] = colorant\"#14213d\";\n",
        "my_color_palette[3] = colorant\"#ffecd1\";\n",
        "my_color_palette[4] = colorant\"rgb(49,52,58)\";\n",
        "my_color_palette[5] = colorant\"#c0d6df\";\n",
        "my_color_palette[6] = colorant\"#000000\";"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fa22e1d-ba02-4d58-9f89-1192406a5127",
      "metadata": {
        "id": "8fa22e1d-ba02-4d58-9f89-1192406a5127"
      },
      "source": [
        "### Load and clean the historical data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4b147bb-6a2c-4f3d-9ffd-9a2ff849045d",
      "metadata": {
        "id": "e4b147bb-6a2c-4f3d-9ffd-9a2ff849045d"
      },
      "source": [
        "We gathered a daily open-high-low-close `dataset` for each firm in the [S&P500](https://en.wikipedia.org/wiki/S%26P_500) since `01-03-2018` until `03-13-2024`, along with data for a few exchange-traded funds and volatility products during that time. We load the `orignal_dataset` by calling the `MyPortfolioDataSet()` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da692a0d-49a1-4b09-b8aa-61d9536133b9",
      "metadata": {
        "id": "da692a0d-49a1-4b09-b8aa-61d9536133b9"
      },
      "outputs": [],
      "source": [
        "original_dataset = MyPortfolioDataSet() |> x->x[\"dataset\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c4f3ad7-5b45-4c75-b247-3741fbed8960",
      "metadata": {
        "id": "4c4f3ad7-5b45-4c75-b247-3741fbed8960"
      },
      "source": [
        "Not all tickers in our dataset have the maximum number of trading days for various reasons, e.g., acquisition or de-listing events. Let's collect only those tickers with the maximum number of traditional days. First, let's compute the number of records for a company that we know has a maximum value, e.g., `AAPL,` and save that value in the `maximum_number_trading_days` variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b591290-7f7f-4190-b478-fededf814a97",
      "metadata": {
        "id": "1b591290-7f7f-4190-b478-fededf814a97"
      },
      "outputs": [],
      "source": [
        "maximum_number_trading_days = original_dataset[\"AAPL\"] |> nrow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c3f4ad1-6a0e-46ce-935a-cea5f2d54fe7",
      "metadata": {
        "id": "7c3f4ad1-6a0e-46ce-935a-cea5f2d54fe7"
      },
      "source": [
        "Then, iterate through our data and collect only tickers with `maximum_number_trading_days` records. Save that data in the `dataset::Dict{String,DataFrame}` variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93e31e08-7373-49b1-930a-921958ee07e3",
      "metadata": {
        "id": "93e31e08-7373-49b1-930a-921958ee07e3"
      },
      "outputs": [],
      "source": [
        "dataset = Dict{String,DataFrame}();\n",
        "for (ticker,data) ∈ original_dataset\n",
        "    if (nrow(data) == maximum_number_trading_days)\n",
        "        dataset[ticker] = data;\n",
        "    end\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2c9ab47-5fce-4422-81db-26fe609732ec",
      "metadata": {
        "id": "b2c9ab47-5fce-4422-81db-26fe609732ec"
      },
      "source": [
        "Lastly, let's get a sorted list of firms that we have in cleaned up `dataset` and save it in the `list_of_all_tickers::Array{String,1}` array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6984d226-b228-4c6a-8a33-072a4e8cfaeb",
      "metadata": {
        "id": "6984d226-b228-4c6a-8a33-072a4e8cfaeb"
      },
      "outputs": [],
      "source": [
        "list_of_all_tickers = keys(dataset) |> collect |> x->sort(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5da5236a-7c1d-4964-994f-baee817261c2",
      "metadata": {
        "id": "5da5236a-7c1d-4964-994f-baee817261c2"
      },
      "source": [
        "We compute the expected (annualized) log growth rate by passing the `dataset` and the entire list of firms we have in the dataset (held in the $N\\times{1}$ `list_of_all_tickers` array) to the [log_growth_matrix(...) method](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/equity/#VLQuantitativeFinancePackage.log_growth_matrix).\n",
        "* The result is stored in the `all_firms_return_matrix::Array{Float64,2}` variable, a $T-1\\times{N}$ array of log return values. Each row of `all_firms_return_matrix` corresponds to a time value, while each column corresponds to a firm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c897f26-4098-4138-8006-73775e5c9323",
      "metadata": {
        "id": "9c897f26-4098-4138-8006-73775e5c9323"
      },
      "outputs": [],
      "source": [
        "all_firms_excess_return_matrix = log_growth_matrix(dataset, list_of_all_tickers,\n",
        "    Δt = Δt, risk_free_rate = risk_free_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc486e89-301e-4559-b97b-4f1d8147a270",
      "metadata": {
        "id": "cc486e89-301e-4559-b97b-4f1d8147a270"
      },
      "source": [
        "Extract the growth rate for your `ticker::String` of interest, and save this in the `Rᵢ::Array{Float64,1}` array. This is the observed _in-sample_ data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6df42777-fcae-4870-b284-4f0709a9a807",
      "metadata": {
        "id": "6df42777-fcae-4870-b284-4f0709a9a807"
      },
      "outputs": [],
      "source": [
        "Rᵢ = findfirst(x->x==ticker, list_of_all_tickers) |> i-> all_firms_excess_return_matrix[:,i]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "601615a8-1b27-49b3-934c-ace1caa02baf",
      "metadata": {
        "id": "601615a8-1b27-49b3-934c-ace1caa02baf"
      },
      "source": [
        "## Task 1: Construct the states $\\mathcal{S}$, the emission matrix $\\mathbf{E}$ and transition matrix $\\hat{\\mathbf{T}}$\n",
        "First, consider the states $\\mathcal{S}$. Suppose we put a label (and number) the excess return values, ranging from `super bad = 1,` $\\dots$,` unchanged,` $\\dots$,` super good = N,` where if $R\\ll{0}$, then we are in the `super bad = 1,` state or $R\\gg{0}$ we are in the `super good = N` state (or we are someplace in between).\n",
        "* __Idea__: Use the [cumulative distribution function](https://en.wikipedia.org/wiki/Cumulative_distribution_function) computed from the observed return series $R_{i,1}, \\dots, R_{i,n}$ to partition the actual (historical) excess returns into one of a fixed number of categories. Once we have the categories, compute the probability that category $i$ on the day $k$ is followed by category $j$ on the day $k+1$. These values are entries in the state transition matrix $\\hat{\\mathbf{T}}$.\n",
        "* To start, specify a value for the  `number_of_states` variable, where the `number_of_states` controls how many categories we are using when splitting up the excess return time series. We then set the `states` vector, which holds the states (numbered from `1`$\\rightarrow$`number_of_states`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08cd8fca-674f-4c1a-b066-2b0df00c68a1",
      "metadata": {
        "id": "08cd8fca-674f-4c1a-b066-2b0df00c68a1"
      },
      "outputs": [],
      "source": [
        "number_of_states = 80; # TODO: specify a value here\n",
        "states = range(1,stop=number_of_states) |> collect;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f968703b-ca20-4c32-b26d-db37ae503d0b",
      "metadata": {
        "id": "f968703b-ca20-4c32-b26d-db37ae503d0b"
      },
      "source": [
        "The `states` are hidden from the observer. Next, we set up the emissions matrix $\\mathbf{E}$. For this example, because the states are __fully observable__, i.e., we can see the states directly,  the emission matrix $\\mathbf{E}$ is the identity matrix $\\mathbf{I}$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d04bba8a-a9b8-4697-b6dc-d06dd3643fd4",
      "metadata": {
        "id": "d04bba8a-a9b8-4697-b6dc-d06dd3643fd4"
      },
      "outputs": [],
      "source": [
        "E = diagm(ones(number_of_states))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34ad667f-3b10-4f70-8f90-86a2e2d727c0",
      "metadata": {
        "id": "34ad667f-3b10-4f70-8f90-86a2e2d727c0"
      },
      "source": [
        "### TODO: Estimate the transition matrix $\\hat{\\mathbf{T}}$ from market data\n",
        "To estimate the transition matrix $\\hat{\\mathbf{T}}$, we'll estimate the transition probabilities from the excess return data calculated in the `Prerequisites` section and saved in the `Rᵢ` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f660cb6-6e83-4f72-9da0-983c96b704ef",
      "metadata": {
        "id": "9f660cb6-6e83-4f72-9da0-983c96b704ef"
      },
      "outputs": [],
      "source": [
        "in_sample_dataset = Rᵢ[1:(maximum_number_trading_days-1)] # set of excess return"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ece5b71b-ade2-47ec-8687-a8215d76c201",
      "metadata": {
        "id": "ece5b71b-ade2-47ec-8687-a8215d76c201"
      },
      "source": [
        "Next, we need to model the return data distribution to compute the [cumulative distribution function](https://en.wikipedia.org/wiki/Cumulative_distribution_function). The excess return distribution is a random variable that follows some [probability distribution function](https://en.wikipedia.org/wiki/Probability_distribution). We don't know what that distribution function is, but for now, we assume the excess returns follow a [Laplace distribution](https://en.wikipedia.org/wiki/Laplace_distribution)\n",
        "* We use the [fit_mle function](https://juliastats.org/Distributions.jl/stable/fit/#Distributions.fit_mle-Tuple{Any,%20Any}) exported by the [Distributions.jl package](https://github.com/JuliaStats/Distributions.jl) to fit a [Laplace distribution](https://en.wikipedia.org/wiki/Laplace_distribution) to our our data. We fit the distribution to the full dataset `Ri` and save the distribution in the `d` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66998588-5052-4465-93aa-b55bd0ceb484",
      "metadata": {
        "id": "66998588-5052-4465-93aa-b55bd0ceb484"
      },
      "outputs": [],
      "source": [
        "d = fit_mle(Laplace, Rᵢ); # use the *full* data set to establish the cutoff's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60b417ea-db9b-4110-b837-164543bc7aa5",
      "metadata": {
        "id": "60b417ea-db9b-4110-b837-164543bc7aa5"
      },
      "outputs": [],
      "source": [
        "let\n",
        "\n",
        "    # regions of return -\n",
        "    number_of_samples = 1000;\n",
        "    minimum_obs_growth = minimum(in_sample_dataset);\n",
        "    maximum_obs_growth = maximum(in_sample_dataset);\n",
        "    RA = range(minimum_obs_growth,stop = maximum_obs_growth, length = number_of_samples) |> collect;\n",
        "\n",
        "    X = Array{Float64,2}(undef, number_of_samples,2);\n",
        "    for i ∈ eachindex(RA)\n",
        "\n",
        "        X[i,1] = RA[i];\n",
        "        X[i,2] = cdf(d, RA[i]);\n",
        "    end\n",
        "\n",
        "    plot(X[:,1], X[:,2], lw=3, c=:navy, label=\"Observed P(S ≤ x)\", xminorticks=5, yminorticks=5)\n",
        "    plot!(X[:,1], 1 .- X[:,2], lw=3, c=:deepskyblue1, label=\"Observed P(S > x)\", legend=:left)\n",
        "\n",
        "    xlabel!(\"$(ticker) share price at expiration (x) (USD/share)\", fontsize=18);\n",
        "    ylabel!(\"Risk-neutral Probability\", fontsize=18);\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07c04fe8-4be7-45f9-a2dd-6fed0dd9377d",
      "metadata": {
        "id": "07c04fe8-4be7-45f9-a2dd-6fed0dd9377d"
      },
      "source": [
        "Next, we generate the percentile cutoffs that we use to establish the bounds that correspond to each category of return, i.e., `super bad` or `super good`, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3930c894-f2fa-429f-b457-11e520070faf",
      "metadata": {
        "id": "3930c894-f2fa-429f-b457-11e520070faf"
      },
      "outputs": [],
      "source": [
        "percentage_cutoff = range(0.0,stop=1.0,length=(number_of_states+1)) |> collect;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f060727-c15a-41f0-a93b-c28c01ab7d00",
      "metadata": {
        "id": "5f060727-c15a-41f0-a93b-c28c01ab7d00"
      },
      "source": [
        "Now that we have the cutoffs, compute the lower and upper bound for each potentiual category. To do this, we'll use the [quantile function](https://juliastats.org/Distributions.jl/stable/univariate/#Statistics.quantile-Tuple{UnivariateDistribution,%20Real}) exported by the [Distributions.jl package](https://github.com/JuliaStats/Distributions.jl). For a given `0 ≤ q ≤ 1`, `quantile(d, q)` is the smallest value `x`\n",
        "for which `cdf(d, x) ≥ q`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3539c8bf-92cd-4b37-97c0-3985ce9085a3",
      "metadata": {
        "id": "3539c8bf-92cd-4b37-97c0-3985ce9085a3"
      },
      "outputs": [],
      "source": [
        "bounds = Array{Float64,2}(undef, number_of_states, 3)\n",
        "for s ∈ states\n",
        "    bounds[s,1] = quantile(d,percentage_cutoff[s])\n",
        "    bounds[s,2] = quantile(d,percentage_cutoff[s+1])\n",
        "    bounds[s,3] = s\n",
        "end\n",
        "bounds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66c00e10-e748-46a5-b691-6c6b76b9cae0",
      "metadata": {
        "id": "66c00e10-e748-46a5-b691-6c6b76b9cae0"
      },
      "source": [
        "Now that we have the category bounds, let's take the excess return data and determine which state an excess return observation corresponds to. For each sample in the `in_sample_dataset`:\n",
        "* Classify the sample value into one of the possible categories. Let `state = 1` equal the worst return, and `state = number_of_states` equal the best return. Save these results in the `encoded_in_sample` array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d5bf65-1220-4d1d-85ae-7984043ca677",
      "metadata": {
        "id": "f2d5bf65-1220-4d1d-85ae-7984043ca677"
      },
      "outputs": [],
      "source": [
        "encoded_in_sample = Array{Int64,1}();\n",
        "for i ∈ eachindex(in_sample_dataset)\n",
        "    value = in_sample_dataset[i];\n",
        "\n",
        "    class_index = 1;\n",
        "    for s ∈ states\n",
        "        if (bounds[s,1] ≤ value && value < bounds[s,2])\n",
        "            class_index = s;\n",
        "            break;\n",
        "        end\n",
        "    end\n",
        "    push!(encoded_in_sample, class_index);\n",
        "end\n",
        "encoded_in_sample;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0965ca7d-0448-4de1-ab47-107e35e66c7a",
      "metadata": {
        "id": "0965ca7d-0448-4de1-ab47-107e35e66c7a"
      },
      "source": [
        "In the matrix $\\mathbf{T}$ compute the `counts` for transition from state `i` to state `j`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f2cf498-f07c-4b61-a0aa-14c108376738",
      "metadata": {
        "id": "7f2cf498-f07c-4b61-a0aa-14c108376738"
      },
      "outputs": [],
      "source": [
        "T = zeros(number_of_states, number_of_states)\n",
        "number_insample = length(encoded_in_sample);\n",
        "for i ∈ 2:number_insample\n",
        "    start_index = encoded_in_sample[i-1];\n",
        "    stop_index = encoded_in_sample[i];\n",
        "    T[start_index,stop_index] += 1;\n",
        "end\n",
        "T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d67b77c2-520c-48fa-98e6-4e2c3edc587a",
      "metadata": {
        "id": "d67b77c2-520c-48fa-98e6-4e2c3edc587a"
      },
      "source": [
        "From the `counts` matrix $\\mathbf{T}$, compute the transtion probability matrix $\\hat{\\mathbf{T}}$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bff6e82d-4db3-453b-99c1-094e2d34ac10",
      "metadata": {
        "id": "bff6e82d-4db3-453b-99c1-094e2d34ac10"
      },
      "outputs": [],
      "source": [
        "T̂ = zeros(number_of_states, number_of_states)\n",
        "for row ∈ states\n",
        "    Z = sum(T[row,:]);\n",
        "    for col ∈ states\n",
        "        T̂[row,col] = (1/Z)*T[row,col]\n",
        "    end\n",
        "end\n",
        "T̂"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a695557e-ce39-4690-a1dd-7e4baf3ed5c4",
      "metadata": {
        "id": "a695557e-ce39-4690-a1dd-7e4baf3ed5c4"
      },
      "source": [
        "## Task 2: Simulate the Hidden Markov Model (HMM)\n",
        "To do the simulation, we first build a [`MyHiddenMarkovModel` instance](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/markov/#VLQuantitativeFinancePackage.MyHiddenMarkovModel), which holds the data for our Markov model. We use a [`build(...)` function](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/markov/#VLQuantitativeFinancePackage.build-Tuple{Type{MyHiddenMarkovModel},%20NamedTuple}), which takes information about the `states,` the estimated transition matrix $\\hat{\\mathbf{T}}$, and the emission matrix $\\mathbf{E}$ and returns a [`MyHiddenMarkovModel` instance](https://varnerlab.github.io/VLQuantitativeFinancePackage.jl/dev/markov/#VLQuantitativeFinancePackage.MyHiddenMarkovModel), which we save in the `model` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cc20d87-5a26-4c41-b013-8596faca3802",
      "metadata": {
        "id": "7cc20d87-5a26-4c41-b013-8596faca3802"
      },
      "outputs": [],
      "source": [
        "model = build(MyHiddenMarkovModel, (\n",
        "    states = states,\n",
        "    T = T̂,\n",
        "    E = E\n",
        "));"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a2eea49-8ead-4b9f-8901-fb495ea07744",
      "metadata": {
        "id": "7a2eea49-8ead-4b9f-8901-fb495ea07744"
      },
      "source": [
        "### TODO: Generate the stationary distribution from the estimated $\\hat{\\mathbf{T}}$ matrix\n",
        "Generate the stationary distribution for the estimated transition matrix $\\hat{\\mathbf{T}}$ and use it to construct a [Categorical distribution](https://juliastats.org/Distributions.jl/stable/univariate/#Distributions.Categorical) representing the stationary distrubution, save the [Categorical distribution](https://juliastats.org/Distributions.jl/stable/univariate/#Distributions.Categorical) in the `π̄`-variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca16cd88-78e7-44ca-ac95-06d240610c44",
      "metadata": {
        "id": "ca16cd88-78e7-44ca-ac95-06d240610c44"
      },
      "outputs": [],
      "source": [
        "power_value = 50;\n",
        "π̄ = (T̂^power_value) |> tmp -> Categorical(tmp[1,:]); # TODO: compute the stationary distribution (approx value is ok)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49000384-30bd-41e6-b4c6-66cc41c1dcaf",
      "metadata": {
        "id": "49000384-30bd-41e6-b4c6-66cc41c1dcaf"
      },
      "source": [
        "### TODO: Implement the `MARKOV-SIMULATION` pseudo code to generate hypothetical return sequences\n",
        "Generate 'number_of_paths' example sequences, each containing 'number_of_steps' days. These variables determine the length and number of our hypothetical return sequences. Assume each path starts from a draw from the stationary distribution `π̄.`\n",
        "* Save the simulated return sequences in the `archive::Array{Int64,2}(undef, number_of_steps, number_of_paths)` array, where the `row` index corresponds to a path, and the `col` index corresponds to a day.\n",
        "* We have implemented some shortcut logic to speed up the implementation. To evaluate the Markov model for a `number_of_steps,` issue the command `model(start_state, number_of_steps).` This will compute a chain with `number_of_steps` starting as `start_state` and return the simulated sequence as an `array.`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbb8b2db-0c36-46d7-b973-e8c43428cfa4",
      "metadata": {
        "id": "dbb8b2db-0c36-46d7-b973-e8c43428cfa4"
      },
      "outputs": [],
      "source": [
        "number_of_steps = maximum_number_trading_days;\n",
        "encoded_archive = Array{Int64,2}(undef, number_of_steps, number_of_paths);\n",
        "for i ∈ 1:number_of_paths\n",
        "    start_state = rand(π̄);\n",
        "    tmp = model(start_state, number_of_steps)\n",
        "    for j ∈ 1:number_of_steps\n",
        "        encoded_archive[j,i] = tmp[j]\n",
        "    end\n",
        "end\n",
        "encoded_archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff261b1d-798e-4e21-a0b2-f5e931a4e044",
      "metadata": {
        "id": "ff261b1d-798e-4e21-a0b2-f5e931a4e044"
      },
      "outputs": [],
      "source": [
        "actual_sample_bounds = copy(bounds);\n",
        "actual_sample_bounds[1,1] = minimum(in_sample_dataset);\n",
        "actual_sample_bounds[end,2] = maximum(in_sample_dataset)\n",
        "actual_sample_bounds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee888229-ce9d-4547-80b2-d952cd0f02b8",
      "metadata": {
        "id": "ee888229-ce9d-4547-80b2-d952cd0f02b8"
      },
      "source": [
        "### Decode operation\n",
        "To turn the state $s\\in\\mathcal{S}$ back into an excess return value, we need to __decode__ the state. To do this, let's construct a [Normal distribution](https://en.wikipedia.org/wiki/Normal_distribution) describing the observed return values associated with each state in the `encoded_in_sample` dataset.\n",
        "* We collect the observed excess return samples associated with a particular state $s$, store them in a `tmp` array, and use [Maximum Likelihood Estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) to estimate a [Normal distribution exported from the Distributions.jl package](https://juliastats.org/Distributions.jl/stable/univariate/#Distributions.Normal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79ed0a2e-d912-4c0b-89e2-272fe2019baa",
      "metadata": {
        "id": "79ed0a2e-d912-4c0b-89e2-272fe2019baa"
      },
      "outputs": [],
      "source": [
        "decode_distribution_model = Dict{Int,Normal}()\n",
        "for s ∈ states\n",
        "\n",
        "    # what indexes correspond to state s\n",
        "    index_collection_state_s = findall(x-> x == s, encoded_in_sample);\n",
        "    tmp = Array{Float64,1}();\n",
        "    for i ∈ index_collection_state_s\n",
        "        decoded_value = Rᵢ[i];\n",
        "        push!(tmp, decoded_value);\n",
        "    end\n",
        "    decode_distribution_model[s] = fit_mle(Normal,tmp);\n",
        "end\n",
        "decode_distribution_model;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a54ab30-26f6-48ce-82f9-774a74389bc0",
      "metadata": {
        "id": "3a54ab30-26f6-48ce-82f9-774a74389bc0"
      },
      "source": [
        "Then, generate a random value for the excess return by sampling the appropriate [Normal distribution](https://juliastats.org/Distributions.jl/stable/univariate/#Distributions.Normal). We develop `number_of_paths` trajectories, each containing `number_of_steps` values. We store these values in the `decoded_archive` variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8637b805-d114-40d9-8be9-e59c2adf9072",
      "metadata": {
        "id": "8637b805-d114-40d9-8be9-e59c2adf9072"
      },
      "outputs": [],
      "source": [
        "in_sample_decoded_archive = Array{Float64,2}(undef, number_of_steps, number_of_paths);\n",
        "for i ∈ 1:number_of_paths\n",
        "    for j ∈ 1:number_of_steps\n",
        "        s = encoded_archive[j,i];\n",
        "        in_sample_decoded_archive[j,i] =  decode_distribution_model[s] |> d -> rand(d)\n",
        "    end\n",
        "end\n",
        "in_sample_decoded_archive # actual excess growth value"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdd08fd6-1141-4b44-a199-c8a6a843f5eb",
      "metadata": {
        "id": "fdd08fd6-1141-4b44-a199-c8a6a843f5eb"
      },
      "source": [
        "### Visualize an example in-sample return trajectory\n",
        "`Unhide` the code block to see how we plotted the observed (red) and simulated (blue) excess growth rate values for a randomly selected sample model generated sample path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d89ebce-06a7-42ef-b4d6-6811b3faab75",
      "metadata": {
        "id": "8d89ebce-06a7-42ef-b4d6-6811b3faab75"
      },
      "outputs": [],
      "source": [
        "let\n",
        "    index_to_plot = rand(1:number_of_paths);\n",
        "    plot(in_sample_decoded_archive[:,index_to_plot], linetype=:steppost, label=\"Simulated i = $(index_to_plot)\",\n",
        "        bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent)\n",
        "    plot!(in_sample_dataset, linetype=:steppost, c=:red, label=\"Observed\")\n",
        "    xlabel!(\"Trading day index\", fintsize=18)\n",
        "    ylabel!(\"Excess Annual Growth Rate $(ticker) (AU)\", fontsize=18)\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ff8f397-6b0a-446b-91fb-f1a6b79c05da",
      "metadata": {
        "id": "0ff8f397-6b0a-446b-91fb-f1a6b79c05da"
      },
      "source": [
        "`Unhide` the code block below to see how we plotted the observed and simulated excess annual growth rate distribution for the in-sample data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ed9e13a-463c-436b-94bb-0dc846839229",
      "metadata": {
        "id": "0ed9e13a-463c-436b-94bb-0dc846839229"
      },
      "outputs": [],
      "source": [
        "let\n",
        "    q = plot();\n",
        "    density!(in_sample_decoded_archive[:,1], lw=2, c=:deepskyblue1, label=\"Simulated\",\n",
        "        bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent)\n",
        "    for i ∈ 2:number_of_paths\n",
        "        density!(in_sample_decoded_archive[:,i], lw=1, c=:deepskyblue1, label=\"\")\n",
        "    end\n",
        "    density!(in_sample_dataset, c=:red, lw=3, label=\"Observed\")\n",
        "    xlabel!(\"Excess Annual Growth Rate $(ticker) (1/year)\", fontsize=18)\n",
        "    ylabel!(\"Probability Density (AU)\", fontsize=18)\n",
        "    current()\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29ec234e-0b0c-47bd-b1a3-fc5cc506dccb",
      "metadata": {
        "id": "29ec234e-0b0c-47bd-b1a3-fc5cc506dccb"
      },
      "source": [
        "### Check: Are the predicted and observed in-sample distributions the same?\n",
        "If our Markov model is correct, then the observed excess growth rate distribution and the excess growth distribution calculated by our model should look like they are drawn from the same distribution. To check this hypothesis, use [the ApproximateTwoSampleKSTest exported by the HypothesisTests.jl package](https://github.com/JuliaStats/HypothesisTests.jl) with the hypotheses:\n",
        "* `H0:null hypothesis` is that `x` and `y` are drawn from the same distribution against the `H1:alternative hypothesis` that `x` and `y` come from different distributions.\n",
        "\n",
        "Let's run [the ApproximateTwoSampleKSTest function](https://github.com/JuliaStats/HypothesisTests.jl) on a single (randomly selected) example trajectory to see what happens (most of the time, we fail to reject `H0`, i.e., the test suggests `x` and `y` are from the same distribution):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9586c74c-7ef9-4909-b2ae-93c9d59b0884",
      "metadata": {
        "id": "9586c74c-7ef9-4909-b2ae-93c9d59b0884"
      },
      "outputs": [],
      "source": [
        "ApproximateTwoSampleKSTest(in_sample_dataset,in_sample_decoded_archive[:,rand(1:number_of_paths)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed3bab38-c2c9-4ea0-ba64-460496e67196",
      "metadata": {
        "id": "ed3bab38-c2c9-4ea0-ba64-460496e67196"
      },
      "source": [
        "However, we have `number_of_paths` example trajectories (not just one), so let's do the same test on each sample and compute an overall expected score. Specify a `pvalue_cutoff` value to check against. If the test returns `pvalue > pvalue_cutoff,` then we fail to reject `H0:null hypothesis`, i.e., `x` and `y` appear to be drawn from the same distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f8f968c-b823-4f24-b618-2f59ba866749",
      "metadata": {
        "id": "0f8f968c-b823-4f24-b618-2f59ba866749"
      },
      "outputs": [],
      "source": [
        "let\n",
        "    pvalue_cutoff = 0.05; # cutoff\n",
        "    pass_counter = 0;\n",
        "    for i ∈ 1:number_of_paths\n",
        "        test_value = ApproximateTwoSampleKSTest(in_sample_dataset,in_sample_decoded_archive[:,i]) |> pvalue\n",
        "        if (test_value > pvalue_cutoff)\n",
        "            pass_counter += 1 # we pass (fail to reject) x and y are from the same distribution\n",
        "        end\n",
        "    end\n",
        "    println(\"Pass percentage: $((pass_counter/number_of_paths)*100)%\")\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "770cbbac-b10b-490a-a2bd-730332a18ff0",
      "metadata": {
        "id": "770cbbac-b10b-490a-a2bd-730332a18ff0"
      },
      "source": [
        "## Task 4: What does our Jump model do?\n",
        "In this task, we explore a modified Markov model that includes jumps. Suppose every so often, instead of transitioning to the next state by sampling the transition matrix, we jump to a __tail state__ of the cumulative distribution. We then stay in one of the tail states for a random number of steps, governed by a [Possion distribution](https://en.wikipedia.org/wiki/Poisson_distribution).\n",
        "\n",
        "To explore this idea, we built [a `MyHiddenMarkovModelWithJumps` instance](src/Types.jl), which holds the same data as the non-jump model. However, we now have two new parameters: the `ϵ::Float64` parameter controls the frequency with which we observe jumps, and the `λ::Int64` parameter is the mean number of events that occur in a given time frame.\n",
        "\n",
        "We save this model in the `jump_model::MyHiddenMarkovModelWithJumps` variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1528dc3-d8b0-4843-96a1-90c284a9e208",
      "metadata": {
        "id": "e1528dc3-d8b0-4843-96a1-90c284a9e208"
      },
      "outputs": [],
      "source": [
        "jump_model = let\n",
        "\n",
        "    model = build(MyHiddenMarkovModelWithJumps, (\n",
        "        states = states,\n",
        "        T = T̂,\n",
        "        E = E,\n",
        "        ϵ = 0.0001, # fraction of steps that we have a jump event\n",
        "        λ = 63, # mean number of jump events\n",
        "    ));\n",
        "\n",
        "    model;\n",
        "end;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd9497e7-2630-4c38-8865-650ccbf2dad3",
      "metadata": {
        "id": "bd9497e7-2630-4c38-8865-650ccbf2dad3"
      },
      "source": [
        "__Sample__: Next, we sample the `jump_model::MyHiddenMarkovModelWithJumps` model. Sampling the model results in the `encoded_archive_with_jumps::Array{Float64,2}` array, which holds sample paths (alternative futures) on the columns and time steps on the rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42ef79bc-7623-4493-b5e9-5a221f1bdf72",
      "metadata": {
        "scrolled": true,
        "id": "42ef79bc-7623-4493-b5e9-5a221f1bdf72"
      },
      "outputs": [],
      "source": [
        "encoded_archive_with_jumps = let\n",
        "    encoded_archive = Array{Int64,2}(undef, number_of_steps, number_of_paths);\n",
        "    for i ∈ 1:number_of_paths\n",
        "        start_state = rand(π̄);\n",
        "\n",
        "        @show i\n",
        "\n",
        "        tmp = jump_model(start_state, number_of_steps)\n",
        "        for j ∈ 1:number_of_steps\n",
        "            encoded_archive[j,i] = tmp[j]\n",
        "        end\n",
        "    end\n",
        "    encoded_archive\n",
        "end;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60de46f4-96dc-4898-828b-34588464f250",
      "metadata": {
        "id": "60de46f4-96dc-4898-828b-34588464f250"
      },
      "source": [
        "__Decode__: We then decode the encoded states and save the decoded values in the `in_sample_decoded_archive_with_jumps::Array{Float64,2}` array. Each row is a return value at the time step, while each column is a sample path, i.e., an alternative universe in which our process is running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e53df465-b047-4100-8556-ccb2e0fad2e8",
      "metadata": {
        "id": "e53df465-b047-4100-8556-ccb2e0fad2e8"
      },
      "outputs": [],
      "source": [
        "in_sample_decoded_archive_with_jumps = let\n",
        "    in_sample_decoded_archive = Array{Float64,2}(undef, number_of_steps, number_of_paths);\n",
        "    for i ∈ 1:number_of_paths\n",
        "        for j ∈ 1:number_of_steps\n",
        "            s = encoded_archive_with_jumps[j,i];\n",
        "            in_sample_decoded_archive[j,i] =  decode_distribution_model[s] |> d -> rand(d)\n",
        "        end\n",
        "    end\n",
        "    in_sample_decoded_archive # actual excess growth value\n",
        "end;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeed7f31-f0e6-4fc9-a29c-7dbbe3eeb332",
      "metadata": {
        "id": "eeed7f31-f0e6-4fc9-a29c-7dbbe3eeb332"
      },
      "outputs": [],
      "source": [
        "in_sample_decoded_archive_with_jumps"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "572fb764-59e1-48d0-be97-4d3d4944b081",
      "metadata": {
        "id": "572fb764-59e1-48d0-be97-4d3d4944b081"
      },
      "source": [
        "`Unhide` the code block below to see how we plotted the observed and simulated excess annual growth rate distribution for the in-sample data. These simulated returns are generated using the jump model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63aedf77-0fe4-4d78-927e-ed293fb916f3",
      "metadata": {
        "id": "63aedf77-0fe4-4d78-927e-ed293fb916f3"
      },
      "outputs": [],
      "source": [
        "let\n",
        "    q = plot();\n",
        "    density!(in_sample_decoded_archive_with_jumps[:,1], lw=2, c=:deepskyblue1, label=\"Simulated\",\n",
        "        bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent)\n",
        "    for i ∈ 2:number_of_paths\n",
        "        density!(in_sample_decoded_archive_with_jumps[:,i], lw=1, c=:deepskyblue1, label=\"\")\n",
        "    end\n",
        "    density!(in_sample_dataset, c=:red, lw=3, label=\"Observed\")\n",
        "    xlabel!(\"Excess Annual Growth Rate $(ticker) (1/year)\", fontsize=18)\n",
        "    ylabel!(\"Probability Density (AU)\", fontsize=18)\n",
        "    current()\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc991805-cad9-42cf-afb7-a56ac752ee51",
      "metadata": {
        "id": "bc991805-cad9-42cf-afb7-a56ac752ee51"
      },
      "source": [
        "### Check: Are the predicted jump model returns and observed in-sample distributions the same?\n",
        "If our jump Markov model is correct, then the observed excess growth rate distribution and the excess growth distribution calculated by our jump model should look like they are drawn from the same distribution. To check this hypothesis, use [the ApproximateTwoSampleKSTest exported by the HypothesisTests.jl package](https://github.com/JuliaStats/HypothesisTests.jl) with the hypotheses:\n",
        "* `H0:null hypothesis` is that `x` and `y` are drawn from the same distribution against the `H1:alternative hypothesis` that `x` and `y` come from different distributions.\n",
        "\n",
        "Let's run [the ApproximateTwoSampleKSTest function](https://github.com/JuliaStats/HypothesisTests.jl) on a single (randomly selected) example trajectory to see what happens (most of the time, we fail to reject `H0`, i.e., the test suggests `x` and `y` are from the same distribution):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca0d2a95-fc07-4e4d-b708-edcab332403c",
      "metadata": {
        "id": "ca0d2a95-fc07-4e4d-b708-edcab332403c"
      },
      "outputs": [],
      "source": [
        "let\n",
        "    pvalue_cutoff = 0.05; # 95% cutoff\n",
        "    pass_counter = 0;\n",
        "    for i ∈ 1:number_of_paths\n",
        "        test_value = ApproximateTwoSampleKSTest(in_sample_dataset,in_sample_decoded_archive_with_jumps[:,i]) |> pvalue\n",
        "        if (test_value > pvalue_cutoff)\n",
        "            pass_counter += 1 # we pass (fail to reject) x and y are from the same distribution\n",
        "        end\n",
        "    end\n",
        "    println(\"Pass percentage: $((pass_counter/number_of_paths)*100)%\")\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbaf5577-029f-44dc-8fd6-17f6c572b73d",
      "metadata": {
        "id": "fbaf5577-029f-44dc-8fd6-17f6c572b73d"
      },
      "source": [
        "### Visualize an example in-sample jump return trajectory\n",
        "`Unhide` the code block to see how we plotted the observed (red) and simulated (blue) excess growth rate values for a randomly selected sample model generated sample path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23ffa117-0762-4dd4-9b31-fe062b9e198b",
      "metadata": {
        "id": "23ffa117-0762-4dd4-9b31-fe062b9e198b"
      },
      "outputs": [],
      "source": [
        "let\n",
        "    index_to_plot = rand(1:number_of_paths);\n",
        "    index_to_plot = 79;\n",
        "    plot(in_sample_decoded_archive_with_jumps[:,index_to_plot], linetype=:steppost, label=\"Simulated i = $(index_to_plot)\",\n",
        "        bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent)\n",
        "    plot!(in_sample_dataset[1:(number_of_steps-1)], linetype=:steppost, c=:red, label=\"Observed\")\n",
        "    xlabel!(\"Trading day index\", fintsize=18)\n",
        "    ylabel!(\"Excess Annual Growth Rate $(ticker) (AU)\", fontsize=18)\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b933490-4ad2-4a14-8e3e-e1e29b9c1c58",
      "metadata": {
        "id": "6b933490-4ad2-4a14-8e3e-e1e29b9c1c58"
      },
      "source": [
        "### Volatility clustering of the simulated dataset\n",
        "Next, let's consider volatility clustering. Volatility clustering is determined by examining the autocorrelation of the absolute values of the excess growth rate for different lag values. In actual data, we expect a positive absolute autocorrelation for short lags. Volatility clustering indicates that periods of high volatility, such as significant changes in returns, tend to occur close together in time.\n",
        "\n",
        "### Summary\n",
        "`Unhide` the code block below to see how we computed and plotted the [autocorrelation function](https://en.wikipedia.org/wiki/Autocorrelation) for the absolute values of the simulated and observed out-of-sample excess growth rates.\n",
        "* The observed out-of-sample dataset (red line) shows a positive autocorrelation for lags less than approximately `10 days` at a 99% confidence level. This suggests the market has a memory of approximately 10 days or less following large disruptions.\n",
        "* The excess growth rate trajectories produced by the Jump Markov model (blue line) also show volatility clustering; thus, this model captures the clustering of high-volatility events."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4027ded-da05-4780-aded-f01746a9ad36",
      "metadata": {
        "id": "c4027ded-da05-4780-aded-f01746a9ad36"
      },
      "outputs": [],
      "source": [
        "let\n",
        "\n",
        "    theme(:dark)\n",
        "    gain_color = colorant\"#06d6a0\";\n",
        "    loss_color = colorant\"#ef476f\";\n",
        "\n",
        "    # generate a random index -\n",
        "    random_index = rand(1:number_of_paths);\n",
        "    random_index = 50\n",
        "    number_of_steps = 252;\n",
        "\n",
        "    L = number_of_steps;\n",
        "    τ  = range(1,step=1,stop=(L-1));\n",
        "    AC_observed = autocor(abs.(Rᵢ), τ);\n",
        "    AC_simulation = autocor(abs.(in_sample_decoded_archive_with_jumps[:,random_index]), τ);\n",
        "\n",
        "     plot(AC_observed, label=\"Observed\", lw=1, c=:red,\n",
        "         bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent, linetype=:steppost)\n",
        "\n",
        "    plot(AC_observed,  label=\"Observed\", linetype=:steppost, foreground_color_axis=:white,\n",
        "        foreground_color_grid=\"white\", framestyle = :box, bg = :black,\n",
        "        foreground_color_border = :white, legend_font_color = :white, legend_background_color=my_color_palette[4],\n",
        "        fg_legend = :transparent, foreground_color=:white, foreground_color_text=:white,\n",
        "        yguidefontcolor=:white, xguidefontcolor=:white, legend=:topright, c=my_color_palette[3])\n",
        "\n",
        "    plot!(AC_simulation, c=gain_color, lw=1,label=\"Simulation (i = $(random_index))\", linetype=:steppost)\n",
        "\n",
        "    LINE = (1.96/sqrt(number_of_steps))*ones(number_of_steps-1);\n",
        "    plot!(LINE, label=\"95% confidence\", lw=2, c=:white, ls=:dash)\n",
        "    plot!(-LINE, label=\"\", lw=2, c=:white, ls=:dash)\n",
        "    xlabel!(\"Lag (trading day)\", fontsize=18)\n",
        "    ylabel!(\"$(ticker) autocorrelation |growth| (AU)\", fontsize=18)\n",
        "\n",
        "     # dump\n",
        "    #savefig(joinpath(_PATH_TO_FIGURES, \"Fig-$(ticker)-ExcessGrowthRate-VolClustering-Daily-HMM-BB.svg\"))\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a4350c3-0ec1-427c-8cfe-9256ec7e6d79",
      "metadata": {
        "id": "5a4350c3-0ec1-427c-8cfe-9256ec7e6d79"
      },
      "source": [
        "### Task 4: Save the HMM model and other data to a file\n",
        "In the project for this module, we'll use the hidden Markov Model (HMM) we developed here. Let's save the model to disk to save some time later on. Use the [save(...) method exported by the JLD2.jl package](https://github.com/JuliaIO/JLD2.jl.git) to write a [model file in HDF5 binary format](https://en.wikipedia.org/wiki/Hierarchical_Data_Format). First, we specify a `path` in the `path_to_save_file` variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1b9e7fd-11a1-478f-ad9a-6623308bb2cf",
      "metadata": {
        "id": "b1b9e7fd-11a1-478f-ad9a-6623308bb2cf"
      },
      "outputs": [],
      "source": [
        "path_to_save_file = joinpath(_PATH_TO_DATA,\"HMM-WJ-$(ticker)-daily-aggregate.jld2\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c75575ed-6fff-40e2-99c7-7ff13c97769a",
      "metadata": {
        "id": "c75575ed-6fff-40e2-99c7-7ff13c97769a"
      },
      "source": [
        "Then we write an [`HDF5 binary file`](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) holding our data to the location specified by `path_to_save_file.` We use the [save(...) function exported by the JLD2.jl package to write a binary save file](https://github.com/JuliaIO/JLD2.jl.git) (later we'll use to the `load(...)` function to reload this data):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3f0a983-431e-4a6f-9cdd-974def7b966f",
      "metadata": {
        "id": "d3f0a983-431e-4a6f-9cdd-974def7b966f"
      },
      "outputs": [],
      "source": [
        "save(path_to_save_file, Dict(\"model\"=>model, \"jump_model\" => jump_model,\n",
        "        \"decode\"=>decode_distribution_model, \"stationary\"=>π̄,\n",
        "        \"insampledataset\"=>in_sample_dataset, \"encoded_archive\" => encoded_archive, \"encoded_archive_with_jumps\" => encoded_archive_with_jumps,\n",
        "        \"in_sample_decoded_archive_with_jumps\" => in_sample_decoded_archive_with_jumps,\n",
        "        \"in_sample_decoded_archive\" => in_sample_decoded_archive));"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c17389a-3c86-45fb-a649-d6611f6720ef",
      "metadata": {
        "id": "2c17389a-3c86-45fb-a649-d6611f6720ef"
      },
      "source": [
        "## Disclaimer and Risks\n",
        "__This content is offered solely for training and informational purposes__. No offer or solicitation to buy or sell securities or derivative products or any investment or trading advice or strategy is made, given, or endorsed by the teaching team.\n",
        "\n",
        "__Trading involves risk__. Carefully review your financial situation before investing in securities, futures contracts, options, or commodity interests. Past performance, whether actual or indicated by historical tests of strategies, is no guarantee of future performance or success. Trading is generally inappropriate for someone with limited resources, investment or trading experience, or a low-risk tolerance.  Only risk capital that is not required for living expenses.\n",
        "\n",
        "__You are fully responsible for any investment or trading decisions you make__. You should decide solely based on your financial circumstances, investment or trading objectives, risk tolerance, and liquidity needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0493e14a-295b-4291-8dc8-805ed18446d8",
      "metadata": {
        "id": "0493e14a-295b-4291-8dc8-805ed18446d8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Julia 1.11.3",
      "language": "julia",
      "name": "julia-1.11"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}